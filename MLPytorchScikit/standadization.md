O que Ã© a PadronizaÃ§Ã£o (Standardization)?
A padronizaÃ§Ã£o Ã© uma tÃ©cnica de prÃ©-processamento que transforma os dados para que cada feature (atributo) tenha uma mÃ©dia igual a 0 e um desvio padrÃ£o igual a 1.

A fÃ³rmula para padronizar uma feature 
ğ‘¥
x Ã©:

ğ‘§
=
ğ‘¥
âˆ’
ğœ‡
ğœ
z= 
Ïƒ
xâˆ’Î¼
â€‹
 
Onde:

ğœ‡
Î¼: MÃ©dia dos valores da feature.
ğœ
Ïƒ: Desvio padrÃ£o dos valores da feature.
ğ‘§
z: Valor padronizado.
ApÃ³s a padronizaÃ§Ã£o, os valores estarÃ£o em uma escala comum, centrados em 0 e variando com base no desvio padrÃ£o.

Por que a padronizaÃ§Ã£o ajuda na funÃ§Ã£o de custo?
A padronizaÃ§Ã£o impacta diretamente no processo de otimizaÃ§Ã£o do modelo, influenciando como a funÃ§Ã£o de custo Ã© minimizada. Vamos explorar as razÃµes:

1. Escalas uniformes para as features
Em conjuntos de dados, as features podem ter escalas muito diferentes. Por exemplo:
Idade: 
0
âˆ’
100
0âˆ’100
Renda anual: 
10.000
âˆ’
1.000.000
10.000âˆ’1.000.000
Quando as escalas sÃ£o muito diferentes, os pesos (
ğ‘¤
w) associados a cada feature tambÃ©m precisam se ajustar para compensar essas diferenÃ§as, tornando o processo de treinamento mais difÃ­cil.
A padronizaÃ§Ã£o garante que todas as features estejam na mesma escala, evitando que uma feature com valores maiores domine o cÃ¡lculo da funÃ§Ã£o de custo.
2. Melhor comportamento da descida do gradiente
A descida do gradiente depende dos gradientes das features para atualizar os pesos. Se uma feature tem valores muito maiores que as outras, os gradientes tambÃ©m serÃ£o desbalanceados.
Isso pode causar oscilaÃ§Ãµes ou passos muito pequenos na direÃ§Ã£o da otimizaÃ§Ã£o, tornando o processo mais lento ou instÃ¡vel.
Com a padronizaÃ§Ã£o, os gradientes tÃªm magnitudes mais uniformes, permitindo que a descida do gradiente converja de forma mais eficiente.
3. Forma da funÃ§Ã£o de custo
A funÃ§Ã£o de custo (como o erro quadrÃ¡tico mÃ©dio, MSE) Ã© mais fÃ¡cil de otimizar quando os dados estÃ£o padronizados.
Sem padronizaÃ§Ã£o, a funÃ§Ã£o de custo pode ter o formato de um vale inclinado (com curvas acentuadas em algumas direÃ§Ãµes e suaves em outras). Isso Ã© chamado de vale em forma de elipse.
Com padronizaÃ§Ã£o, a funÃ§Ã£o de custo assume uma forma mais esfÃ©rica, facilitando os passos consistentes na descida do gradiente.
4. Evita dependÃªncia excessiva na taxa de aprendizado
Com dados nÃ£o padronizados, a escolha de uma boa taxa de aprendizado (
ğœ‚
Î·) pode ser muito difÃ­cil, porque os gradientes podem variar muito em magnitude.
Padronizar os dados reduz essa variaÃ§Ã£o, permitindo que o modelo funcione bem com uma taxa de aprendizado mais consistente.
Exemplos prÃ¡ticos:
Antes da padronizaÃ§Ã£o:

Idade: 
[
20
,
30
,
40
,
50
]
[20,30,40,50]
Renda anual: 
[
20000
,
30000
,
40000
,
50000
]
[20000,30000,40000,50000]
A feature "Renda" domina a otimizaÃ§Ã£o porque tem valores maiores.
Depois da padronizaÃ§Ã£o:

Idade (padronizada): 
[
âˆ’
1.34
,
âˆ’
0.67
,
0.67
,
1.34
]
[âˆ’1.34,âˆ’0.67,0.67,1.34]
Renda (padronizada): 
[
âˆ’
1.34
,
âˆ’
0.67
,
0.67
,
1.34
]
[âˆ’1.34,âˆ’0.67,0.67,1.34]
Agora ambas as features contribuem de forma equilibrada na funÃ§Ã£o de custo.